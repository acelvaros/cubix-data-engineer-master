{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33af2b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccf0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f067e1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'socketserver' has no attribute 'UnixStreamServer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mst\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msf\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SZABGAB\\cubix_data_engineer_pyspark_tutorial\\.venv\\Lib\\site-packages\\pyspark\\__init__.py:71\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InheritableThread, inheritable_thread_target\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstoragelevel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StorageLevel\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccumulators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Accumulator, AccumulatorParam\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserializers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MarshalSerializer, CPickleSerializer\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtaskcontext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TaskContext, BarrierTaskContext, BarrierTaskInfo\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SZABGAB\\cubix_data_engineer_pyspark_tutorial\\.venv\\Lib\\site-packages\\pyspark\\accumulators.py:324\u001b[39m\n\u001b[32m    320\u001b[39m         \u001b[38;5;28msuper\u001b[39m().shutdown()\n\u001b[32m    321\u001b[39m         \u001b[38;5;28mself\u001b[39m.server_close()\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mAccumulatorUnixServer\u001b[39;00m(\u001b[43msocketserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUnixStreamServer\u001b[49m):\n\u001b[32m    325\u001b[39m     server_shutdown = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    327\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mself\u001b[39m, socket_path: \u001b[38;5;28mstr\u001b[39m, RequestHandlerClass: Type[socketserver.BaseRequestHandler]\n\u001b[32m    329\u001b[39m     ):\n",
      "\u001b[31mAttributeError\u001b[39m: module 'socketserver' has no attribute 'UnixStreamServer'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as st\n",
    "import pyspark.sql.functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a57013",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparkSession' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m spark = (\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mSparkSession\u001b[49m\n\u001b[32m      3\u001b[39m     .builder\n\u001b[32m      4\u001b[39m     .appName(\u001b[33m\"\u001b[39m\u001b[33mPySpark tutorial\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     .master(\u001b[33m\"\u001b[39m\u001b[33mlocal[*]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     .getOrCreate()\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'SparkSession' is not defined"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"PySpark tutorial\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5272b68",
   "metadata": {},
   "source": [
    "#### Read/Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "839ab475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  1|  Alice| 20|\n",
      "|  2|    Bob| 25|\n",
      "|  3|Charlie| 30|\n",
      "|  4|  David| 35|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, \"Alice\", 20),\n",
    "    (2, \"Bob\", 25),\n",
    "    (3, \"Charlie\", 30),\n",
    "    (4, \"David\", 35)\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"name\", \"age\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbed57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = st.StructType(\n",
    "    [\n",
    "        st.StructField(\"id\", st.IntegerType(), True),\n",
    "        st.StructField(\"name\", st.StringType(), True),\n",
    "        st.StructField(\"age\", st.IntegerType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac95604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "|    United States|          Singapore|   25|\n",
      "|    United States|            Grenada|   54|\n",
      "|       Costa Rica|      United States|  477|\n",
      "|          Senegal|      United States|   29|\n",
      "|    United States|   Marshall Islands|   44|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read_csv = spark.read.csv(\"C:\\\\Users\\\\SZABGAB\\\\cubix_data_engineer_pyspark_tutorial\\\\src\\\\data\\\\2010-summary.csv\", header=True)\n",
    "\n",
    "df_read_csv.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89a7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read_csv = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .load(\"C:\\\\Users\\\\SZABGAB\\\\cubix_data_engineer_pyspark_tutorial\\\\src\\\\data\\\\2010-summary.csv\")\n",
    ")\n",
    "\n",
    "df_read_csv.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2024-09-01 00:05:51|  2024-09-01 00:45:03|              1|          9.8|         1|                 N|         138|          48|           1|       47.8|10.25|    0.5|      13.3|        6.94|                  1.0|       79.79|                 2.5|       1.75|\n",
      "|       1| 2024-09-01 00:59:35|  2024-09-01 01:03:43|              1|          0.5|         1|                 N|         140|         141|           1|        5.1|  3.5|    0.5|       3.0|         0.0|                  1.0|        13.1|                 2.5|        0.0|\n",
      "|       2| 2024-09-01 00:25:00|  2024-09-01 00:34:37|              2|         2.29|         1|                 N|         238|         152|           2|       13.5|  1.0|    0.5|       0.0|         0.0|                  1.0|        16.0|                 0.0|        0.0|\n",
      "|       2| 2024-09-01 00:31:00|  2024-09-01 00:46:52|              1|          5.2|         1|                 N|          93|         130|           1|       24.7|  1.0|    0.5|      4.55|         0.0|                  1.0|       31.75|                 0.0|        0.0|\n",
      "|       2| 2024-09-01 00:11:57|  2024-09-01 00:30:41|              2|         2.26|         1|                 N|          79|         231|           1|       17.0|  1.0|    0.5|       4.4|         0.0|                  1.0|        26.4|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:30:13|  2024-09-01 00:36:44|              1|          1.2|         1|                 N|          43|         239|           1|        8.6|  3.5|    0.5|       2.7|         0.0|                  1.0|        16.3|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:59:24|  2024-09-01 01:01:00|              1|          0.1|         5|                 N|         143|         143|           3|       0.01|  0.0|    0.0|       0.0|         0.0|                  1.0|        1.01|                 0.0|        0.0|\n",
      "|       1| 2024-09-01 00:08:28|  2024-09-01 00:39:06|              4|          9.8|         1|                 N|          93|         161|           1|       44.3|  3.5|    0.5|      9.85|         0.0|                  1.0|       59.15|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:06:07|  2024-09-01 00:11:38|              1|          0.6|         1|                 N|         170|         137|           1|        6.5|  3.5|    0.5|       2.9|         0.0|                  1.0|        14.4|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:20:28|  2024-09-01 00:36:06|              1|          4.1|         1|                 N|          79|         263|           1|       19.1|  3.5|    0.5|       4.8|         0.0|                  1.0|        28.9|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read_parquet = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"parquet\")\n",
    "    .load(\"C:\\\\Users\\\\SZABGAB\\\\cubix_data_engineer_pyspark_tutorial\\\\src\\\\data\\\\yellow_tripdata_2024-09.parquet\")\n",
    ")\n",
    "\n",
    "df_read_parquet.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfa7a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0965e81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3633030"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read_parquet.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b190e49",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/C:/Users/SZABGAB/cubix_data_engineer_pyspark_tutorial/src/data/yellow_tripdata.parquet already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_read_parquet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mSZABGAB\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mcubix_data_engineer_pyspark_tutorial\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43msrc\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mdata\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43myellow_tripdata.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SZABGAB\\cubix_data_engineer_pyspark_tutorial\\.venv\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:1721\u001b[39m, in \u001b[36mDataFrameWriter.parquet\u001b[39m\u001b[34m(self, path, mode, partitionBy, compression)\u001b[39m\n\u001b[32m   1719\u001b[39m     \u001b[38;5;28mself\u001b[39m.partitionBy(partitionBy)\n\u001b[32m   1720\u001b[39m \u001b[38;5;28mself\u001b[39m._set_opts(compression=compression)\n\u001b[32m-> \u001b[39m\u001b[32m1721\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SZABGAB\\cubix_data_engineer_pyspark_tutorial\\.venv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SZABGAB\\cubix_data_engineer_pyspark_tutorial\\.venv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [PATH_ALREADY_EXISTS] Path file:/C:/Users/SZABGAB/cubix_data_engineer_pyspark_tutorial/src/data/yellow_tripdata.parquet already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "df_read_parquet.write.parquet(\"C:\\\\Users\\\\SZABGAB\\\\cubix_data_engineer_pyspark_tutorial\\\\src\\\\data\\\\yellow_tripdata.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43dd0e8",
   "metadata": {},
   "source": [
    "#### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "09f39413",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"parquet\")\n",
    "    .load(\"C:\\\\Users\\\\SZABGAB\\\\cubix_data_engineer_pyspark_tutorial\\\\src\\\\data\\\\yellow_tripdata_2024-09.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d008a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+-------------------+-----------------+------------------+---------------------+------------------+--------------------+-------------------+\n",
      "|summary|          VendorID|   passenger_count|    trip_distance|        RatecodeID|store_and_fwd_flag|     PULocationID|     DOLocationID|      payment_type|       fare_amount|             extra|            mta_tax|       tip_amount|      tolls_amount|improvement_surcharge|      total_amount|congestion_surcharge|        Airport_fee|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+-------------------+-----------------+------------------+---------------------+------------------+--------------------+-------------------+\n",
      "|  count|           3633030|           3149299|          3633030|           3149299|           3149299|          3633030|          3633030|           3633030|           3633030|           3633030|            3633030|          3633030|           3633030|              3633030|           3633030|             3149299|            3149299|\n",
      "|   mean|1.7724431122231306|1.3032055705095007| 5.74146907952812| 2.267361403283715|              NULL|163.1819519794772|162.7876585109399|1.0645070368260103|20.003841718897263|1.3332638045928606|0.47880214311470043|3.309012661607199| 0.576684981956552|   0.9600296171515246|  28.5390979045304|  2.2198141554676134|0.15697239290394466|\n",
      "| stddev|0.4199700575585026|0.7649121294863445|494.0948263287312|10.638666368995478|              NULL|64.85019891860168|69.99713198734946|0.6803698263865253|19.887829631131755|1.8025235190776907|0.13335959125688257|4.218428204702532|2.2736529005745236|   0.2626378795517542|24.754769525879478|  0.8951147051660812| 0.5189316385423182|\n",
      "|    min|                 1|                 0|              0.0|                 1|                 N|                1|                1|                 0|            -999.0|              -7.5|               -0.5|            -88.0|            -114.2|                 -1.0|           -1000.0|                -2.5|              -1.75|\n",
      "|    max|                 6|                 9|        330397.59|                99|                 Y|              265|              265|                 4|            1862.2|             14.44|               10.5|            500.0|            476.35|                  1.0|           1886.02|                 2.5|               1.75|\n",
      "+-------+------------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+------------------+-------------------+-----------------+------------------+---------------------+------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1475c1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|VendorID|passenger_count|\n",
      "+--------+---------------+\n",
      "|       1|              1|\n",
      "|       1|              1|\n",
      "|       2|              2|\n",
      "|       2|              1|\n",
      "|       2|              2|\n",
      "+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_df.select(\"VendorID\", \"passenger_count\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e27bae28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|VendorID|passenger_count|\n",
      "+--------+---------------+\n",
      "|       1|              1|\n",
      "|       1|              1|\n",
      "|       2|              2|\n",
      "|       2|              1|\n",
      "|       2|              2|\n",
      "+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_df.select(taxi_df.VendorID, taxi_df.passenger_count).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d47065be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|VendorID|passenger_count|\n",
      "+--------+---------------+\n",
      "|       1|              1|\n",
      "|       1|              1|\n",
      "|       2|              2|\n",
      "|       2|              1|\n",
      "|       2|              2|\n",
      "+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_df.select(sf.col(\"VendorID\"), sf.col(\"passenger_count\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c60db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2024-09-01 00:08:28|  2024-09-01 00:39:06|              4|          9.8|         1|                 N|          93|         161|           1|       44.3|  3.5|    0.5|      9.85|         0.0|                  1.0|       59.15|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:57:30|  2024-09-01 01:40:20|              2|         14.5|         1|                 N|         132|          91|           1|       64.6| 2.75|    0.5|     13.77|         0.0|                  1.0|       82.62|                 0.0|       1.75|\n",
      "|       1| 2024-09-01 00:40:52|  2024-09-01 00:59:15|              2|          5.2|         1|                 N|         234|          87|           1|       24.0|  3.5|    0.5|       3.0|         0.0|                  1.0|        32.0|                 2.5|        0.0|\n",
      "|       2| 2024-09-01 00:33:49|  2024-09-01 01:04:30|              2|        16.86|         2|                 N|         132|          48|           1|       70.0|  0.0|    0.5|     16.19|        6.94|                  1.0|       98.88|                 2.5|       1.75|\n",
      "|       1| 2024-09-01 00:50:46|  2024-09-01 01:29:27|              2|         10.0|         1|                 N|          43|          61|           1|       46.4|  3.5|    0.5|     10.25|         0.0|                  1.0|       61.65|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    taxi_df\n",
    "    .where(\n",
    "        (sf.col(\"trip_distance\") > 5)\n",
    "        & (sf.col(\"passenger_count\") > 1)\n",
    "    )\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8a20399e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2024-09-01 00:05:51|  2024-09-01 00:45:03|              1|          9.8|         1|                 N|         138|          48|           1|       47.8|10.25|    0.5|      13.3|        6.94|                  1.0|       79.79|                 2.5|       1.75|\n",
      "|       1| 2024-09-01 00:59:35|  2024-09-01 01:03:43|              1|          0.5|         1|                 N|         140|         141|           1|        5.1|  3.5|    0.5|       3.0|         0.0|                  1.0|        13.1|                 2.5|        0.0|\n",
      "|       2| 2024-09-01 00:25:00|  2024-09-01 00:34:37|              2|         2.29|         1|                 N|         238|         152|           2|       13.5|  1.0|    0.5|       0.0|         0.0|                  1.0|        16.0|                 0.0|        0.0|\n",
      "|       2| 2024-09-01 00:31:00|  2024-09-01 00:46:52|              1|          5.2|         1|                 N|          93|         130|           1|       24.7|  1.0|    0.5|      4.55|         0.0|                  1.0|       31.75|                 0.0|        0.0|\n",
      "|       2| 2024-09-01 00:11:57|  2024-09-01 00:30:41|              2|         2.26|         1|                 N|          79|         231|           1|       17.0|  1.0|    0.5|       4.4|         0.0|                  1.0|        26.4|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_df.where(sf.col(\"store_and_fwd_flag\") == 'N').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a19acb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2024-09-01 00:23:40|  2024-09-01 00:43:46|              1|          3.9|         1|                 Y|         142|          42|           1|       20.5|  3.5|    0.5|      6.35|         0.0|                  1.0|       31.85|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:16:25|  2024-09-01 00:20:14|              1|          0.8|         1|                 Y|          48|         143|           1|        6.5|  3.5|    0.5|       2.3|         0.0|                  1.0|        13.8|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:47:47|  2024-09-01 00:54:12|              3|          1.2|         1|                 Y|         186|          68|           2|        7.9|  3.5|    0.5|       0.0|         0.0|                  1.0|        12.9|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:17:34|  2024-09-01 00:48:23|              1|          4.4|         1|                 Y|         230|          87|           1|       28.9|  3.5|    0.5|      6.75|         0.0|                  1.0|       40.65|                 2.5|        0.0|\n",
      "|       2| 2024-09-01 00:13:00|  2024-09-01 00:17:30|              1|         0.88|         1|                 Y|         249|          68|           1|        6.5|  1.0|    0.5|      3.45|         0.0|                  1.0|       14.95|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_df.where(sf.col(\"store_and_fwd_flag\") != 'N').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58dceab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-------------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|total_amount_with_all_tax|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-------------------------+\n",
      "|       1| 2024-09-01 00:05:51|  2024-09-01 00:45:03|              1|          9.8|         1|                 N|         138|          48|           1|       47.8|10.25|    0.5|      13.3|        6.94|                  1.0|       79.79|                 2.5|       1.75|                    84.04|\n",
      "|       1| 2024-09-01 00:59:35|  2024-09-01 01:03:43|              1|          0.5|         1|                 N|         140|         141|           1|        5.1|  3.5|    0.5|       3.0|         0.0|                  1.0|        13.1|                 2.5|        0.0|                     15.6|\n",
      "|       2| 2024-09-01 00:25:00|  2024-09-01 00:34:37|              2|         2.29|         1|                 N|         238|         152|           2|       13.5|  1.0|    0.5|       0.0|         0.0|                  1.0|        16.0|                 0.0|        0.0|                     16.0|\n",
      "|       2| 2024-09-01 00:31:00|  2024-09-01 00:46:52|              1|          5.2|         1|                 N|          93|         130|           1|       24.7|  1.0|    0.5|      4.55|         0.0|                  1.0|       31.75|                 0.0|        0.0|                    31.75|\n",
      "|       2| 2024-09-01 00:11:57|  2024-09-01 00:30:41|              2|         2.26|         1|                 N|          79|         231|           1|       17.0|  1.0|    0.5|       4.4|         0.0|                  1.0|        26.4|                 2.5|        0.0|                     28.9|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    taxi_df\n",
    "    .where(\n",
    "        ~(sf.col(\"store_and_fwd_flag\") != 'N')\n",
    "    )\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f6f9e",
   "metadata": {},
   "source": [
    "#### withColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "580b4bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+-------------------------+\n",
      "|total_amount|congestion_surcharge|Airport_fee|total_amount_with_all_tax|\n",
      "+------------+--------------------+-----------+-------------------------+\n",
      "|       79.79|                 2.5|       1.75|                    84.04|\n",
      "|        13.1|                 2.5|        0.0|                     15.6|\n",
      "|        16.0|                 0.0|        0.0|                     16.0|\n",
      "|       31.75|                 0.0|        0.0|                    31.75|\n",
      "|        26.4|                 2.5|        0.0|                     28.9|\n",
      "+------------+--------------------+-----------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_df = (\n",
    "    taxi_df\n",
    "    .withColumn(\n",
    "        \"total_amount_with_all_tax\",\n",
    "        sf.col(\"total_amount\") + sf.col(\"congestion_surcharge\") + sf.col(\"Airport_fee\")\n",
    "    )\n",
    ")\n",
    "\n",
    "(\n",
    "    taxi_df\n",
    "    .select(\n",
    "        sf.col(\"total_amount\"),\n",
    "        sf.col(\"congestion_surcharge\"),\n",
    "        sf.col(\"Airport_fee\"),        \n",
    "        sf.col(\"total_amount_with_all_tax\")\n",
    "    )\n",
    ").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36beecaf",
   "metadata": {},
   "source": [
    "#### withColumnRenamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1e24a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|total_amount_with_taxes|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------------+\n",
      "|       1| 2024-09-01 00:05:51|  2024-09-01 00:45:03|              1|          9.8|         1|                 N|         138|          48|           1|       47.8|10.25|    0.5|      13.3|        6.94|                  1.0|       79.79|                 2.5|       1.75|                  84.04|\n",
      "|       1| 2024-09-01 00:59:35|  2024-09-01 01:03:43|              1|          0.5|         1|                 N|         140|         141|           1|        5.1|  3.5|    0.5|       3.0|         0.0|                  1.0|        13.1|                 2.5|        0.0|                   15.6|\n",
      "|       2| 2024-09-01 00:25:00|  2024-09-01 00:34:37|              2|         2.29|         1|                 N|         238|         152|           2|       13.5|  1.0|    0.5|       0.0|         0.0|                  1.0|        16.0|                 0.0|        0.0|                   16.0|\n",
      "|       2| 2024-09-01 00:31:00|  2024-09-01 00:46:52|              1|          5.2|         1|                 N|          93|         130|           1|       24.7|  1.0|    0.5|      4.55|         0.0|                  1.0|       31.75|                 0.0|        0.0|                  31.75|\n",
      "|       2| 2024-09-01 00:11:57|  2024-09-01 00:30:41|              2|         2.26|         1|                 N|          79|         231|           1|       17.0|  1.0|    0.5|       4.4|         0.0|                  1.0|        26.4|                 2.5|        0.0|                   28.9|\n",
      "|       1| 2024-09-01 00:30:13|  2024-09-01 00:36:44|              1|          1.2|         1|                 N|          43|         239|           1|        8.6|  3.5|    0.5|       2.7|         0.0|                  1.0|        16.3|                 2.5|        0.0|                   18.8|\n",
      "|       1| 2024-09-01 00:59:24|  2024-09-01 01:01:00|              1|          0.1|         5|                 N|         143|         143|           3|       0.01|  0.0|    0.0|       0.0|         0.0|                  1.0|        1.01|                 0.0|        0.0|                   1.01|\n",
      "|       1| 2024-09-01 00:08:28|  2024-09-01 00:39:06|              4|          9.8|         1|                 N|          93|         161|           1|       44.3|  3.5|    0.5|      9.85|         0.0|                  1.0|       59.15|                 2.5|        0.0|                  61.65|\n",
      "|       1| 2024-09-01 00:06:07|  2024-09-01 00:11:38|              1|          0.6|         1|                 N|         170|         137|           1|        6.5|  3.5|    0.5|       2.9|         0.0|                  1.0|        14.4|                 2.5|        0.0|                   16.9|\n",
      "|       1| 2024-09-01 00:20:28|  2024-09-01 00:36:06|              1|          4.1|         1|                 N|          79|         263|           1|       19.1|  3.5|    0.5|       4.8|         0.0|                  1.0|        28.9|                 2.5|        0.0|                   31.4|\n",
      "|       1| 2024-09-01 00:39:39|  2024-09-01 00:40:04|              1|          0.0|         1|                 N|         262|         262|           3|        3.0|  3.5|    0.5|       0.0|         0.0|                  1.0|         8.0|                 2.5|        0.0|                   10.5|\n",
      "|       1| 2024-09-01 00:40:13|  2024-09-01 00:40:37|              1|          0.0|         1|                 N|         262|         262|           2|        3.0|  3.5|    0.5|       0.0|         0.0|                  1.0|         8.0|                 2.5|        0.0|                   10.5|\n",
      "|       1| 2024-09-01 00:42:42|  2024-09-01 00:42:57|              1|          0.0|         1|                 N|         262|         262|           2|        3.0|  3.5|    0.5|       0.0|         0.0|                  1.0|         8.0|                 2.5|        0.0|                   10.5|\n",
      "|       1| 2024-09-01 00:58:17|  2024-09-01 01:09:22|              1|          1.8|         1|                 N|         142|         141|           1|       12.8|  3.5|    0.5|       1.0|         0.0|                  1.0|        18.8|                 2.5|        0.0|                   21.3|\n",
      "|       2| 2024-09-01 00:36:54|  2024-09-01 00:46:21|              1|         1.27|         1|                 N|          79|           4|           1|       10.0|  1.0|    0.5|       2.0|         0.0|                  1.0|        17.0|                 2.5|        0.0|                   19.5|\n",
      "|       2| 2024-09-01 00:57:52|  2024-09-01 01:06:48|              1|         1.56|         1|                 N|          79|         211|           1|       10.7|  1.0|    0.5|       2.0|         0.0|                  1.0|        17.7|                 2.5|        0.0|                   20.2|\n",
      "|       1| 2024-09-01 00:05:33|  2024-09-01 00:09:23|              1|          0.8|         1|                 N|         249|          90|           1|        6.5|  3.5|    0.5|       2.3|         0.0|                  1.0|        13.8|                 2.5|        0.0|                   16.3|\n",
      "|       1| 2024-09-01 00:29:49|  2024-09-01 00:45:45|              2|          3.6|         1|                 N|          68|         232|           1|       20.5|  3.5|    0.5|       5.1|         0.0|                  1.0|        30.6|                 2.5|        0.0|                   33.1|\n",
      "|       2| 2024-09-01 00:09:35|  2024-09-01 00:41:39|              1|         9.14|         1|                 N|          68|          89|           1|       42.9|  1.0|    0.5|       5.0|        6.94|                  1.0|       59.84|                 2.5|        0.0|                  62.34|\n",
      "|       2| 2024-09-01 00:24:50|  2024-09-01 00:37:56|              1|         1.26|         1|                 N|         246|         100|           1|       12.8|  1.0|    0.5|      3.56|         0.0|                  1.0|       21.36|                 2.5|        0.0|                  23.86|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_df = taxi_df.withColumnRenamed(\"total_amount_with_all_tax\", \"total_amount_with_taxes\")\n",
    "taxi_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff523055",
   "metadata": {},
   "source": [
    "#### Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7fa2dc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2024-09-01 00:05:51|  2024-09-01 00:45:03|              1|          9.8|         1|                 N|         138|          48|           1|       47.8|10.25|    0.5|      13.3|        6.94|                  1.0|       79.79|                 2.5|       1.75|\n",
      "|       1| 2024-09-01 00:59:35|  2024-09-01 01:03:43|              1|          0.5|         1|                 N|         140|         141|           1|        5.1|  3.5|    0.5|       3.0|         0.0|                  1.0|        13.1|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_df = taxi_df.drop(sf.col(\"total_amount_with_all_tax\"))\n",
    "taxi_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45d5dce",
   "metadata": {},
   "source": [
    "#### Group by (order by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6dba25af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|PULocationID| count|\n",
      "+------------+------+\n",
      "|         132|188147|\n",
      "|         237|166033|\n",
      "|         161|153988|\n",
      "|         236|149284|\n",
      "|         186|120393|\n",
      "|         162|117163|\n",
      "|         230|113531|\n",
      "|         138|111112|\n",
      "|         142|107537|\n",
      "|          68|104585|\n",
      "+------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    taxi_df\n",
    "    .groupBy(sf.col(\"PULocationID\"))\n",
    "    .count()\n",
    "    .sort(sf.col(\"count\"), ascending=False)\n",
    "    .show(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638b47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+--------------+\n",
      "|payment_type| total_amount|average_amount|\n",
      "+------------+-------------+--------------+\n",
      "|           1|81,090,276.01|         31.13|\n",
      "|           0|11,577,187.59|         23.93|\n",
      "|           2|10,682,143.65|         23.99|\n",
      "|           3|   198,527.68|          7.84|\n",
      "|           4|   135,263.93|          1.83|\n",
      "+------------+-------------+--------------+\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "(\n",
    "    taxi_df\n",
    "    .groupBy(sf.col(\"payment_type\"))\n",
    "    .agg(\n",
    "        sf.sum(\"total_amount\").alias(\"total_amount\"),\n",
    "        sf.avg(\"total_amount\").alias(\"average_amount\")\n",
    "    )\n",
    "    .sort(sf.col(\"total_amount\"), ascending=False)\n",
    "    .withColumn(\"total_amount\", sf.format_number(sf.col(\"total_amount\"), 2)) # converted to string with the transformation\n",
    "    .withColumn(\"average_amount\", sf.format_number(sf.col(\"average_amount\"), 2)) # converted to string with the transformation\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe8bfe8",
   "metadata": {},
   "source": [
    "#### Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40e0f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+\n",
      "|employee_id|   name|department_id|\n",
      "+-----------+-------+-------------+\n",
      "|          1|  Alice|          101|\n",
      "|          2|    Bob|          102|\n",
      "|          3|Charlie|          103|\n",
      "|          4|  David|          101|\n",
      "|          5|    Eve|          104|\n",
      "|          6|  Frank|          105|\n",
      "|          7|  Grace|          102|\n",
      "|          8|  Helen|          106|\n",
      "|          9|    Ian|          103|\n",
      "|         10|   Jack|          104|\n",
      "+-----------+-------+-------------+\n",
      "\n",
      "None\n",
      "+-------------+---------------+\n",
      "|department_id|department_name|\n",
      "+-------------+---------------+\n",
      "|          101|             HR|\n",
      "|          102|        Finance|\n",
      "|          103|             IT|\n",
      "|          104|      Marketing|\n",
      "|          105|          Sales|\n",
      "|          107|     Operations|\n",
      "+-------------+---------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Dataframe 1: employees\n",
    "employees_data = [\n",
    "    (1, \"Alice\", \"101\"),\n",
    "    (2, \"Bob\", \"102\"),\n",
    "    (3, \"Charlie\", \"103\"),\n",
    "    (4, \"David\", \"101\"),\n",
    "    (5, \"Eve\", \"104\"),\n",
    "    (6, \"Frank\", \"105\"),\n",
    "    (7, \"Grace\", \"102\"),\n",
    "    (8, \"Helen\", \"106\"),\n",
    "    (9, \"Ian\", \"103\"),\n",
    "    (10, \"Jack\", \"104\")\n",
    "]\n",
    "employees_columns = [\"employee_id\", \"name\", \"department_id\"]\n",
    "employees_df = spark.createDataFrame(employees_data, employees_columns)\n",
    "\n",
    "# Dataframe 2: departments\n",
    "departments_data = [\n",
    "    (101, \"HR\"),\n",
    "    (102, \"Finance\"),\n",
    "    (103, \"IT\"),\n",
    "    (104, \"Marketing\"),\n",
    "    (105, \"Sales\"),\n",
    "    (107, \"Operations\")\n",
    "]\n",
    "departments_columns = [\"department_id\", \"department_name\"]\n",
    "departments_df = spark.createDataFrame(departments_data, departments_columns)\n",
    "\n",
    "print(employees_df.show())\n",
    "print(departments_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317b9108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------+---------------+\n",
      "|department_id|employee_id|   name|department_name|\n",
      "+-------------+-----------+-------+---------------+\n",
      "|          101|          1|  Alice|             HR|\n",
      "|          101|          4|  David|             HR|\n",
      "|          102|          2|    Bob|        Finance|\n",
      "|          102|          7|  Grace|        Finance|\n",
      "|          103|          3|Charlie|             IT|\n",
      "|          103|          9|    Ian|             IT|\n",
      "|          104|          5|    Eve|      Marketing|\n",
      "|          104|         10|   Jack|      Marketing|\n",
      "|          105|          6|  Frank|          Sales|\n",
      "+-------------+-----------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inner_join_df = (\n",
    "    employees_df\n",
    "    .join(departments_df, \"department_id\", how=\"inner\")\n",
    "    .sort(sf.col(\"department_id\"))\n",
    ")\n",
    "\n",
    "inner_join_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eee3e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------+---------------+\n",
      "|department_id|employee_id|   name|department_name|\n",
      "+-------------+-----------+-------+---------------+\n",
      "|          101|          4|  David|             HR|\n",
      "|          101|          1|  Alice|             HR|\n",
      "|          102|          7|  Grace|        Finance|\n",
      "|          102|          2|    Bob|        Finance|\n",
      "|          103|          9|    Ian|             IT|\n",
      "|          103|          3|Charlie|             IT|\n",
      "|          104|         10|   Jack|      Marketing|\n",
      "|          104|          5|    Eve|      Marketing|\n",
      "|          105|          6|  Frank|          Sales|\n",
      "|          107|       NULL|   NULL|     Operations|\n",
      "+-------------+-----------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "left_join_df = (\n",
    "    employees_df\n",
    "    .join(departments_df, \"department_id\", how=\"left\")\n",
    "    .sort(sf.col(\"department_id\"))\n",
    ")\n",
    "\n",
    "left_join_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297fe354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------+---------------+\n",
      "|department_id|employee_id|   name|department_name|\n",
      "+-------------+-----------+-------+---------------+\n",
      "|          101|          1|  Alice|             HR|\n",
      "|          101|          4|  David|             HR|\n",
      "|          102|          2|    Bob|        Finance|\n",
      "|          102|          7|  Grace|        Finance|\n",
      "|          103|          3|Charlie|             IT|\n",
      "|          103|          9|    Ian|             IT|\n",
      "|          104|          5|    Eve|      Marketing|\n",
      "|          104|         10|   Jack|      Marketing|\n",
      "|          105|          6|  Frank|          Sales|\n",
      "|          106|          8|  Helen|           NULL|\n",
      "|          107|       NULL|   NULL|     Operations|\n",
      "+-------------+-----------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outer_join_df = (\n",
    "    employees_df\n",
    "    .join(departments_df, \"department_id\", how=\"outer\")\n",
    "    .sort(sf.col(\"department_id\"))\n",
    ")\n",
    "\n",
    "outer_join_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3eefae",
   "metadata": {},
   "source": [
    "#### SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b2c05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"parquet\")\n",
    "    .load(\"C:\\\\Users\\\\SZABGAB\\\\cubix_data_engineer_pyspark_tutorial\\\\src\\\\data\\\\yellow_tripdata_2024-09.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4bd9641",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.createOrReplaceTempView(\"taxi_temp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82130639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2024-09-01 00:05:51|  2024-09-01 00:45:03|              1|          9.8|         1|                 N|         138|          48|           1|       47.8|10.25|    0.5|      13.3|        6.94|                  1.0|       79.79|                 2.5|       1.75|\n",
      "|       1| 2024-09-01 00:59:35|  2024-09-01 01:03:43|              1|          0.5|         1|                 N|         140|         141|           1|        5.1|  3.5|    0.5|       3.0|         0.0|                  1.0|        13.1|                 2.5|        0.0|\n",
      "|       2| 2024-09-01 00:25:00|  2024-09-01 00:34:37|              2|         2.29|         1|                 N|         238|         152|           2|       13.5|  1.0|    0.5|       0.0|         0.0|                  1.0|        16.0|                 0.0|        0.0|\n",
      "|       2| 2024-09-01 00:31:00|  2024-09-01 00:46:52|              1|          5.2|         1|                 N|          93|         130|           1|       24.7|  1.0|    0.5|      4.55|         0.0|                  1.0|       31.75|                 0.0|        0.0|\n",
      "|       2| 2024-09-01 00:11:57|  2024-09-01 00:30:41|              2|         2.26|         1|                 N|          79|         231|           1|       17.0|  1.0|    0.5|       4.4|         0.0|                  1.0|        26.4|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:30:13|  2024-09-01 00:36:44|              1|          1.2|         1|                 N|          43|         239|           1|        8.6|  3.5|    0.5|       2.7|         0.0|                  1.0|        16.3|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:59:24|  2024-09-01 01:01:00|              1|          0.1|         5|                 N|         143|         143|           3|       0.01|  0.0|    0.0|       0.0|         0.0|                  1.0|        1.01|                 0.0|        0.0|\n",
      "|       1| 2024-09-01 00:08:28|  2024-09-01 00:39:06|              4|          9.8|         1|                 N|          93|         161|           1|       44.3|  3.5|    0.5|      9.85|         0.0|                  1.0|       59.15|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:06:07|  2024-09-01 00:11:38|              1|          0.6|         1|                 N|         170|         137|           1|        6.5|  3.5|    0.5|       2.9|         0.0|                  1.0|        14.4|                 2.5|        0.0|\n",
      "|       1| 2024-09-01 00:20:28|  2024-09-01 00:36:06|              1|          4.1|         1|                 N|          79|         263|           1|       19.1|  3.5|    0.5|       4.8|         0.0|                  1.0|        28.9|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM taxi_temp_view LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba351fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|Airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2024-09-01 00:57:30|  2024-09-01 01:40:20|              2|         14.5|         1|                 N|         132|          91|           1|       64.6| 2.75|    0.5|     13.77|         0.0|                  1.0|       82.62|                 0.0|       1.75|\n",
      "|       2| 2024-09-01 00:19:05|  2024-09-01 00:37:21|              1|        10.37|         1|                 N|         138|         216|           1|       40.1|  6.0|    0.5|       7.4|         0.0|                  1.0|       56.75|                 0.0|       1.75|\n",
      "|       2| 2024-09-01 00:28:49|  2024-09-01 01:18:09|              1|        14.69|         1|                 N|          87|         223|           1|       66.0|  1.0|    0.5|      14.2|         0.0|                  1.0|        85.2|                 2.5|        0.0|\n",
      "|       2| 2024-09-01 00:33:49|  2024-09-01 01:04:30|              2|        16.86|         2|                 N|         132|          48|           1|       70.0|  0.0|    0.5|     16.19|        6.94|                  1.0|       98.88|                 2.5|       1.75|\n",
      "|       2| 2024-09-01 00:37:56|  2024-09-01 01:07:34|              1|        20.69|         2|                 N|         132|         140|           1|       70.0|  0.0|    0.5|     16.19|        6.94|                  1.0|       98.88|                 2.5|       1.75|\n",
      "|       1| 2024-09-01 00:19:39|  2024-09-01 00:52:04|              1|         17.4|         2|                 N|         132|         230|           1|       70.0| 4.25|    0.5|      10.0|        6.94|                  1.0|       92.69|                 2.5|       1.75|\n",
      "|       2| 2024-09-01 00:47:02|  2024-09-01 01:13:49|              1|        10.17|         1|                 N|         234|         257|           1|       41.5|  1.0|    0.5|      6.08|        6.94|                  1.0|       59.52|                 2.5|        0.0|\n",
      "|       2| 2024-09-01 00:32:58|  2024-09-01 01:04:07|              2|        18.05|         2|                 N|         132|          68|           1|       70.0|  0.0|    0.5|     16.19|        6.94|                  1.0|       98.88|                 2.5|       1.75|\n",
      "|       2| 2024-09-01 00:04:21|  2024-09-01 00:47:54|              4|        12.84|         1|                 N|         132|         189|           1|       56.9|  1.0|    0.5|     11.88|         0.0|                  1.0|       73.03|                 0.0|       1.75|\n",
      "|       2| 2024-09-01 00:37:45|  2024-09-01 01:13:22|              1|        19.08|         1|                 N|         230|         265|           1|       73.0|  1.0|    0.5|     16.99|        6.94|                  1.0|      101.93|                 2.5|        0.0|\n",
      "|       2| 2024-09-01 00:07:25|  2024-09-01 00:40:36|              2|        20.63|         1|                 N|         132|         213|           2|       76.5|  1.0|    0.5|       0.0|        6.94|                  1.0|       87.69|                 0.0|       1.75|\n",
      "|       2| 2024-09-01 00:01:27|  2024-09-01 00:51:35|              1|        38.84|         5|                 N|         138|         265|           2|      100.0|  5.0|    0.0|       0.0|        6.94|                  1.0|      114.69|                 0.0|       1.75|\n",
      "|       1| 2024-09-01 00:30:31|  2024-09-01 00:58:04|              1|         10.2|         1|                 N|         186|          69|           2|       40.8|  3.5|    0.5|       0.0|         0.0|                  1.0|        45.8|                 2.5|        0.0|\n",
      "|       2| 2024-09-01 00:29:34|  2024-09-01 01:01:12|              1|        13.55|         1|                 N|          93|         234|           1|       56.2|  1.0|    0.5|       5.0|        6.94|                  1.0|       73.14|                 2.5|        0.0|\n",
      "|       2| 2024-08-31 23:57:52|  2024-09-01 00:29:43|              1|        18.05|         2|                 N|         132|          42|           1|       70.0|  0.0|    0.5|     12.03|        6.94|                  1.0|       92.22|                 0.0|       1.75|\n",
      "|       2| 2024-09-01 00:03:39|  2024-09-01 00:33:23|              1|        15.71|         4|                 N|         138|         265|           2|       62.5|  6.0|    0.5|       0.0|         0.0|                  1.0|       71.75|                 0.0|       1.75|\n",
      "|       2| 2024-09-01 00:05:17|  2024-09-01 00:44:18|              2|        21.09|         2|                 N|         132|         239|           1|       70.0|  0.0|    0.5|     16.19|        6.94|                  1.0|       98.88|                 2.5|       1.75|\n",
      "|       2| 2024-09-01 00:35:16|  2024-09-01 00:58:39|              1|         16.5|         2|                 N|         132|         170|           1|       70.0|  0.0|    0.5|       0.0|        6.94|                  1.0|       82.69|                 2.5|       1.75|\n",
      "|       2| 2024-09-01 00:04:26|  2024-09-01 00:29:40|              1|        11.06|         4|                 N|         132|         265|           1|       59.0|  1.0|    0.5|     15.38|         0.0|                  1.0|       78.63|                 0.0|       1.75|\n",
      "|       2| 2024-09-01 00:55:37|  2024-09-01 01:26:45|              1|        21.13|         2|                 N|         132|         239|           1|       70.0|  0.0|    0.5|      12.4|        6.94|                  1.0|       95.09|                 2.5|       1.75|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'avg_amount_by_payment_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m spark.sql(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33m    SELECT\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33m        *\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m \u001b[33m        trip_distance > 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m\"\"\"\u001b[39m).show()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mavg_amount_by_payment_type\u001b[49m.show()\n",
      "\u001b[31mNameError\u001b[39m: name 'avg_amount_by_payment_type' is not defined"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        taxi_temp_view\n",
    "    WHERE\n",
    "        trip_distance > 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ff92646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|payment_type| avg(total_amount)|\n",
      "+------------+------------------+\n",
      "|           1|31.132636716912728|\n",
      "|           3| 7.835484864032835|\n",
      "|           2|23.992416616129827|\n",
      "|           4|1.8263854120252212|\n",
      "|           0|23.933110737169443|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_amount_by_payment_type = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        payment_type,\n",
    "        avg(total_amount)\n",
    "    FROM\n",
    "        taxi_temp_view\n",
    "    GROUP BY\n",
    "        payment_type\n",
    "\"\"\")\n",
    "\n",
    "avg_amount_by_payment_type.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c9cce5",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperationException",
     "evalue": "UPDATE TABLE is not supported temporarily.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnsupportedOperationException\u001b[39m             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# createOrReplaceTempView() or any other view creation only supports SELECTing, no UPDATE/INSERT/DELETE\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[33;43m    UPDATE taxi_temp_view\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[33;43m    SET passenger_count = 100\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[33;43m    WHERE\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[33;43m        VendorID = 1\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[33;43m        AND trip_distance = 14.5\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SZABGAB\\cubix_data_engineer_pyspark_tutorial\\.venv\\Lib\\site-packages\\pyspark\\sql\\session.py:1631\u001b[39m, in \u001b[36mSparkSession.sql\u001b[39m\u001b[34m(self, sqlQuery, args, **kwargs)\u001b[39m\n\u001b[32m   1627\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1628\u001b[39m         litArgs = \u001b[38;5;28mself\u001b[39m._jvm.PythonUtils.toArray(\n\u001b[32m   1629\u001b[39m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[32m   1630\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1631\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jsparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1632\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SZABGAB\\cubix_data_engineer_pyspark_tutorial\\.venv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SZABGAB\\cubix_data_engineer_pyspark_tutorial\\.venv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mUnsupportedOperationException\u001b[39m: UPDATE TABLE is not supported temporarily."
     ]
    }
   ],
   "source": [
    "# createOrReplaceTempView() or any other view creation only supports SELECTing, no UPDATE/INSERT/DELETE\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    UPDATE taxi_temp_view\n",
    "    SET passenger_count = 100\n",
    "    WHERE\n",
    "        VendorID = 1\n",
    "        AND trip_distance = 14.5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d196da1",
   "metadata": {},
   "source": [
    "#### Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5f3b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65ec06f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|number|double|\n",
      "+------+------+\n",
      "|     0|     0|\n",
      "|     1|     2|\n",
      "|     2|     4|\n",
      "|     3|     6|\n",
      "|     4|     8|\n",
      "+------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "50000\n",
      "50000\n",
      "Time taken without caching: 27.64 seconds\n"
     ]
    }
   ],
   "source": [
    "data = [(i, i * 2) for i in range(100000)]\n",
    "df = spark.createDataFrame(data, [\"number\", \"double\"])\n",
    "df.show(5)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Repeat an expensive computation twice\n",
    "df_filtered = df.filter(df[\"number\"] % 2 == 0)\n",
    "print(df_filtered.count()) # First computation\n",
    "print(df_filtered.count()) # Second computation\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time taken without caching: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb992632",
   "metadata": {},
   "source": [
    "#### Broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b57d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|product_id|product_names|\n",
      "+----------+-------------+\n",
      "|         1|    Product_1|\n",
      "|         2|    Product_2|\n",
      "|         3|    Product_3|\n",
      "|         4|    Product_4|\n",
      "|         5|    Product_5|\n",
      "+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+-----------+\n",
      "|product_id|   category|\n",
      "+----------+-----------+\n",
      "|         1|Electronics|\n",
      "|         2|   Clothing|\n",
      "|         3|       Toys|\n",
      "|         4|  Groceries|\n",
      "|         5|      Books|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_ids = [i for i in range(1, 3000001)]\n",
    "product_names = [f\"Product_{i}\" for i in range (1, 3000001)]\n",
    "\n",
    "large_data = list(zip(product_ids, product_names))\n",
    "columns = [\"product_id\", \"product_names\"]\n",
    "\n",
    "large_df = spark.createDataFrame(large_data, columns)\n",
    "large_df.show(5)\n",
    "\n",
    "category_data = [(1, \"Electronics\"), (2, \"Clothing\"), (3, \"Toys\"), (4, \"Groceries\"), (5, \"Books\")]\n",
    "category_columns = [\"product_id\", \"category\"]\n",
    "\n",
    "small_df = spark.createDataFrame(category_data, category_columns)\n",
    "small_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "116281c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----------+\n",
      "|product_id|product_names|   category|\n",
      "+----------+-------------+-----------+\n",
      "|         1|    Product_1|Electronics|\n",
      "|         5|    Product_5|      Books|\n",
      "|         3|    Product_3|       Toys|\n",
      "|         2|    Product_2|   Clothing|\n",
      "|         4|    Product_4|  Groceries|\n",
      "+----------+-------------+-----------+\n",
      "\n",
      "Time taken: 30.15 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "joined_df_no_broadcast = large_df.join(small_df, \"product_id\")\n",
    "joined_df_no_broadcast.show(5)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40a20651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-----------+\n",
      "|product_id|product_names|   category|\n",
      "+----------+-------------+-----------+\n",
      "|         1|    Product_1|Electronics|\n",
      "|         2|    Product_2|   Clothing|\n",
      "|         3|    Product_3|       Toys|\n",
      "|         4|    Product_4|  Groceries|\n",
      "|         5|    Product_5|      Books|\n",
      "+----------+-------------+-----------+\n",
      "\n",
      "Time taken: 28.35 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "joined_df_broadcast = large_df.join(sf.broadcast(small_df), \"product_id\")\n",
    "joined_df_broadcast.show(5)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ac30e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without broadcasting\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [product_id#95L, product_names#96, category#109]\n",
      "   +- SortMergeJoin [product_id#95L], [product_id#108L], Inner\n",
      "      :- Sort [product_id#95L ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(product_id#95L, 200), ENSURE_REQUIREMENTS, [plan_id=536]\n",
      "      :     +- Filter isnotnull(product_id#95L)\n",
      "      :        +- Scan ExistingRDD[product_id#95L,product_names#96]\n",
      "      +- Sort [product_id#108L ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(product_id#108L, 200), ENSURE_REQUIREMENTS, [plan_id=537]\n",
      "            +- Filter isnotnull(product_id#108L)\n",
      "               +- Scan ExistingRDD[product_id#108L,category#109]\n",
      "\n",
      "\n",
      "None\n",
      "With broadcasting\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [product_id#95L, product_names#96, category#109]\n",
      "   +- BroadcastHashJoin [product_id#95L], [product_id#108L], Inner, BuildRight, false\n",
      "      :- Filter isnotnull(product_id#95L)\n",
      "      :  +- Scan ExistingRDD[product_id#95L,product_names#96]\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [plan_id=566]\n",
      "         +- Filter isnotnull(product_id#108L)\n",
      "            +- Scan ExistingRDD[product_id#108L,category#109]\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Without broadcasting\")\n",
    "print(large_df.join(small_df, \"product_id\").explain())\n",
    "\n",
    "print(\"With broadcasting\")\n",
    "print(large_df.join(sf.broadcast(small_df), \"product_id\").explain())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5578c7f1",
   "metadata": {},
   "source": [
    "#### week_2_pyspark_homework.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a7cd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as st\n",
    "import pyspark.sql.functions as sf\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"DE - Week 1. Homework\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
